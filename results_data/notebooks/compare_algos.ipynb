{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec, cm\n",
    "FONT_SIZE = 17\n",
    "\n",
    "from random import shuffle, seed\n",
    "SEED_NUMBER=42\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_path = Path().resolve().parent\n",
    "print(proj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_P = proj_path / \"Panigrahy_multidim_OPT.csv\"\n",
    "file_H = proj_path / \"Hetero_multidim_OPT.csv\"\n",
    "file_T = proj_path / \"Triplet_multidim.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "family_list = ['FF',\n",
    "               'FFD', 'FFD-Dyn',\n",
    "               'BFD-T1', 'BFD-T1-Dyn',\n",
    "               'BFD-T2', 'BFD-T2-Dyn',\n",
    "               'BFD-T3', 'BFD-T3-Dyn',\n",
    "               'BF', 'BF-Dyn',\n",
    "               'WFD-T1', 'WFD-T1-Dyn',\n",
    "               'WFD-T2', 'WFD-T2-Dyn',\n",
    "               'WFD-T3', 'WFD-T3-Dyn',\n",
    "               'WF', 'WF-Dyn',\n",
    "               'BCS-DP1', 'BCS-DP1-Dyn', 'BCS-DP1-Bin', \n",
    "               'BCS-DP2', 'BCS-DP2-Dyn', 'BCS-DP2-Bin', \n",
    "               'BCS-DP3', 'BCS-DP3-Dyn', 'BCS-DP3-Bin', \n",
    "               'BCS-NormDP', 'BCS-NormDP-Dyn', 'BCS-NormDP-Bin',\n",
    "               'BCS-L2Norm', 'BCS-L2Norm-Dyn', 'BCS-L2Norm-Bin',\n",
    "               'BCS-TFSum', 'BCS-TFSum-Dyn', 'BCS-TFSum-Bin',\n",
    "               'BCS-TFMin', 'BCS-TFMin-Dyn', 'BCS-TFMin-Bin',\n",
    "               \n",
    "               'BCS', 'BCS-Dyn', 'BCS-Bin',\n",
    "               #'Pairing-BS', 'Pairing-BS-Dyn', 'Pairing-BS-Bin',\n",
    "               #'WFDm-BS', 'WFDm-BS-Dyn',\n",
    "               'MB-Pairing', 'MB-Pairing-Dyn', 'MB-Pairing-Bin',\n",
    "               'MB-WFD', 'MB-WFD-Dyn',\n",
    "               \n",
    "               'meta'\n",
    "              ]\n",
    "\n",
    "def get_family(alg_name):\n",
    "    ssplit = alg_name.split('-')\n",
    "    s = ssplit[0]\n",
    "    if s == 'MB':\n",
    "        if (ssplit[1] == \"BFD\") or (ssplit[1] == \"WFD\"):\n",
    "            s+= \"-WFD\"\n",
    "        elif ssplit[1] == \"Pairing\":\n",
    "            s+= \"-\" + ssplit[1]\n",
    "        \n",
    "        if (\"Dyn\" in alg_name) or (\"Ratio\" in alg_name):\n",
    "            s+=\"-Dyn\"\n",
    "        elif (\"Bin\" in alg_name):\n",
    "            s+=\"-Bin\"\n",
    "        \n",
    "    elif s == 'BCS':\n",
    "        #s+= \"-\" + ssplit[1]\n",
    "        if (\"Dyn\" in alg_name) or (\"Ratio\" in alg_name):\n",
    "            s+=\"-Dyn\"\n",
    "        elif (\"Bin\" in alg_name):\n",
    "            s+=\"-Bin\"\n",
    "\n",
    "    else:\n",
    "        if \"T1\" in alg_name:\n",
    "            s+= \"-T1\"\n",
    "        elif \"T2\" in alg_name:\n",
    "            s+= \"-T2\"\n",
    "        elif \"T3\" in alg_name:\n",
    "            s+= \"-T3\"\n",
    "            \n",
    "        if \"Rank\" in alg_name:\n",
    "            s = \"Fit-Rank\"\n",
    "        \n",
    "        if (\"Dyn\" in alg_name) or (\"Ratio\" in alg_name):\n",
    "            s+=\"-Dyn\"\n",
    "    \n",
    "    if s in family_list:\n",
    "        return s\n",
    "    else:\n",
    "        print(\"Unknown algo name\", alg_name, s)\n",
    "        return -1\n",
    "    \n",
    "def is_family(alg_name, family_name):\n",
    "    fam = get_family(alg_name)\n",
    "    return fam == family_name\n",
    "\n",
    "def create_family_dict(alg_list):\n",
    "    d = defaultdict(list)\n",
    "    \n",
    "    for alg_name in alg_list:\n",
    "        fam = get_family(alg_name)\n",
    "        if fam != -1:\n",
    "            d[fam].append(alg_name)\n",
    "        \n",
    "    return d\n",
    "\n",
    "def get_simple_family(alg_name):\n",
    "    ssplit = alg_name.split('-')\n",
    "    s = ssplit[0]\n",
    "    \n",
    "    if s == 'MB':\n",
    "        if ssplit[1] == \"Pairing\":\n",
    "            return s+\"-Pairing\"\n",
    "        else:\n",
    "            return s+\"-WFD\"\n",
    "    else:\n",
    "        return s\n",
    "    \n",
    "def create_simple_family_dict(alg_list):\n",
    "    d = defaultdict(list)\n",
    "    \n",
    "    for alg_name in alg_list:\n",
    "        fam = get_simple_family(alg_name)\n",
    "        if fam != -1:\n",
    "            d[fam].append(alg_name)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(s):\n",
    "    score = 0\n",
    "    if \"T1\" in s:\n",
    "        score+= 0.1\n",
    "    elif \"T2\" in s:\n",
    "        score+= 0.2\n",
    "    elif \"T3\" in s:\n",
    "        score+= 0.3\n",
    "\n",
    "    if s == \"FF\":\n",
    "        score = 0\n",
    "    elif s.startswith('FF'):\n",
    "        score+= 1\n",
    "    elif s.startswith('BF'):\n",
    "        score+= 2\n",
    "    elif s.startswith('WF'):\n",
    "        score+= 3\n",
    "    elif s.startswith('BCS'):\n",
    "        score+= 4\n",
    "    elif s.startswith('MB-WFD') or s.startswith('MB-BFD'):\n",
    "        score+= 5\n",
    "    elif s.startswith('MB-Pairing'):\n",
    "        score+= 6\n",
    "    elif s.startswith('meta-'):\n",
    "        score+=99\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f90ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_algos(algo_list):\n",
    "    return [x.replace(\"WFDm-BS\", \"MB-WFD\").replace(\"BFDm-BS\", \"MB-BFD\").replace(\"Pairing-BS\", \"MB-Pairing\").replace(\"ReciprocAvg\", \"RecipAvg\") for x in algo_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-custody",
   "metadata": {},
   "source": [
    "## Get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(filename, with_classes=True, **kwargs):\n",
    "    df = pd.read_csv(filename, sep='\\t')\n",
    "    #if with_OPT:\n",
    "    if \"OPT\" in df.columns:\n",
    "        # First 3 columns are ['instance_name', 'LB', 'OPT']\n",
    "        start_cols = 3\n",
    "    else:\n",
    "        start_cols = 2\n",
    "        # First 2 columns are ['instance_name', 'LB']\n",
    "    \n",
    "    # Rename some algorithms\n",
    "    df.columns = rename_algos(df.columns)\n",
    "      \n",
    "    all_column_names = df.columns[start_cols:]\n",
    "    \n",
    "    if (len(all_column_names) % 2) != 0:\n",
    "        print(f\"ERROR: {len(all_column_names)} {len(df.columns)}\")\n",
    "\n",
    "    alg_names = [x for x in all_column_names if not \"_time\" in x]\n",
    "    nb_algos = len(alg_names)\n",
    "    \n",
    "    alg_names_multi = [x for x in alg_names if x.startswith(\"MB-\")]\n",
    "    \n",
    "    # Complement MB results with the solutions of FF\n",
    "    for alg in alg_names_multi:\n",
    "        df.loc[df[alg] == -1, alg] = df['FF']\n",
    "    \n",
    "    for x in alg_names:\n",
    "        if '.' in x:\n",
    "            print(\"Error ALGO NAME:\", x)\n",
    "    \n",
    "    best_LB_OPT = df[\"LB\"].copy()\n",
    "    if \"OPT\" in df.columns:\n",
    "        # complement with optimal values\n",
    "        idx = df[df[\"OPT\"] != -1].index\n",
    "        best_LB_OPT.loc[idx] = df.loc[idx][\"OPT\"]\n",
    "        df.drop(['OPT'], axis=1, inplace=True)\n",
    "    df.insert(2, 'LB_or_OPT', best_LB_OPT)\n",
    "    \n",
    "    df.insert(1, 'n', df['instance_name'].apply(lambda x: int(x.split('_')[1])))\n",
    "    df.insert(2, 'd', df['instance_name'].apply(lambda x: int(x.split('_')[2])))\n",
    "    if with_classes:\n",
    "        df.insert(1, 'class', df['instance_name'].apply(lambda x: x.split('_')[0][5:]))\n",
    "        \n",
    "    df.drop(['instance_name'], axis=1, inplace=True)\n",
    "    \n",
    "    return df, alg_names, alg_names_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d6aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(df, alg_names, by_list, group_as_index=False):\n",
    "    sub_df = df[by_list].copy()\n",
    "    \n",
    "    df[\"best_sol\"] = df[alg_names].min(axis=1)\n",
    "\n",
    "    time_cols = [i+'_timems' for i in alg_names]\n",
    "    \n",
    "    eps = df[alg_names].apply(lambda x: (round(x / df[\"LB_or_OPT\"] - 1, 3))*100) # *100 to get a percentage value\n",
    "    time = df[time_cols].apply(lambda x: round(x, 4))\n",
    "    time.columns = alg_names\n",
    "    diff = df[alg_names].apply(lambda x: x - df[\"LB_or_OPT\"])\n",
    "    diff_best = df[alg_names].apply(lambda x: x - df[\"best_sol\"])\n",
    "    match_LB = df[alg_names].apply(lambda x: x == df[\"LB\"])\n",
    "    \n",
    "    best = df[alg_names].apply(lambda x: x == df[\"best_sol\"])\n",
    "    \n",
    "    eps = pd.concat([sub_df, eps], axis=1).groupby(by=by_list, as_index=group_as_index).mean()\n",
    "    time = pd.concat([sub_df, time], axis=1).groupby(by=by_list, as_index=group_as_index).mean()\n",
    "    diff = pd.concat([sub_df, diff], axis=1).groupby(by=by_list, as_index=group_as_index).mean()\n",
    "    diff_best = pd.concat([sub_df, diff_best], axis=1).groupby(by=by_list, as_index=group_as_index).mean()\n",
    "    \n",
    "    best = pd.concat([sub_df, best], axis=1).groupby(by=by_list, as_index=group_as_index).sum()\n",
    "    match_LB = pd.concat([sub_df, match_LB], axis=1).groupby(by=by_list, as_index=group_as_index).sum()\n",
    "    \n",
    "    return eps, time, diff, diff_best, best, match_LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1619ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_algo_list(algo_list, remove_prefix):\n",
    "    def predicate(alg, remove_prefix):\n",
    "        for s in remove_prefix:\n",
    "            if alg.startswith(s):\n",
    "                #print(\"removing\", alg)\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    l = [alg for alg in algo_list if not predicate(alg, remove_prefix)]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb47413",
   "metadata": {},
   "source": [
    "# Load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d2e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P, all_algos, multi_algos = load_df(file_P, with_classes=True)\n",
    "df_H, _, _ = load_df(file_H, with_classes=True)\n",
    "df_T, _, _ = load_df(file_T, with_classes=True)\n",
    "\n",
    "print(f\"Loaded {len(all_algos)} algos including {len(multi_algos)} MB algos!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909d6b1a",
   "metadata": {},
   "source": [
    "# Compare algos with Unit weights only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70ac369",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_names_unit = [x for x in all_algos if \"-Unit\" in x and not \"T3\" in x]\n",
    "alg_names_unit.insert(0, 'FF')\n",
    "print(f\"There are {len(alg_names_unit)} Unit algos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b2081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out BF and WF algos\n",
    "alg_names_unit = [x for x in alg_names_unit if not \"BF-\" in x and not \"WF-\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1160eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all Centric + Multibin algos\n",
    "unit_results_P = get_results(df_P, alg_names_unit, ['class', 'n', 'd'], group_as_index=True)\n",
    "unit_results_H = get_results(df_H, alg_names_unit, ['class', 'n', 'd'], group_as_index=True)\n",
    "unit_results_T = get_results(df_T, alg_names_unit, ['class', 'n', 'd'], group_as_index=True)\n",
    "\n",
    "# results contains: eps, time, diff, diff_best, best, match_LB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f3584",
   "metadata": {},
   "source": [
    "## Find algos consistently outperformed by others\n",
    "There are none for Centric. Even BF and WF are better than DotProduct1 for some instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_T\n",
    "algs = alg_names_unit\n",
    "\n",
    "nb_instances = df.shape[0]\n",
    "for algo_test in algs:\n",
    "    counts = df[algs].apply(lambda x: x <= df[algo_test]).sum()\n",
    "    l = list(counts[counts == nb_instances].index)\n",
    "    l.remove(algo_test)\n",
    "    if (len(l) > 0):\n",
    "        #to_remove = to_remove.union(l)\n",
    "        print(f\"{algo_test}: {len(l)} are better than me\")\n",
    "        if (len(l) < 10):\n",
    "            print('\\t', l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19234e4",
   "metadata": {},
   "source": [
    "## Find algorithms performing equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa965c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_P\n",
    "algs = alg_names_unit\n",
    "\n",
    "nb_instances = df.shape[0]\n",
    "sub_list = algs.copy()\n",
    "new_list = []\n",
    "for i in range(len(algs)):\n",
    "    algo_test = sub_list.pop(0)\n",
    "    new_list.append(algo_test)\n",
    "    # Find algos performing equally to algo_test\n",
    "    counts = df[sub_list].apply(lambda x: x == df[algo_test]).sum()\n",
    "    l = list(counts[counts == nb_instances].index)\n",
    "    if (len(l) != 0):\n",
    "        # If some are found, remove them from the sub_list\n",
    "        print(f\"{algo_test} identical to: {l}\")\n",
    "        sub_list = [x for x in sub_list if not x in l]\n",
    "    if (len(sub_list) == 0):\n",
    "        break\n",
    "# Sub_list contains 'unique' algos\n",
    "print(f\"There are {len(new_list)} 'unique' algos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476eec5e",
   "metadata": {},
   "source": [
    "## Find best algos for each class and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d19770",
   "metadata": {},
   "outputs": [],
   "source": [
    "algs = alg_names_unit\n",
    "\n",
    "eps = unit_results_P[0]\n",
    "for c in range(1,10): # For Panigrahy dataframe\n",
    "    print(\"\\tClass\", c)\n",
    "    \n",
    "    print(\"\\t\\tPercentage err to LB\")\n",
    "    eps_avg = eps.loc[str(c)][algs].mean()\n",
    "    eps_avg.sort_values(ascending=True, inplace=True)\n",
    "    print(eps_avg.head(10))\n",
    "    \n",
    "    #print(\"\\t\\tAvg. diff to best\")\n",
    "    #diff_best_avg = diff_best.loc[str(c)][algs].mean()\n",
    "    #diff_best_avg.sort_values(ascending=True, inplace=True)\n",
    "    #print(diff_best_avg.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aca4852",
   "metadata": {},
   "outputs": [],
   "source": [
    "algs = alg_names_unit\n",
    "\n",
    "eps = unit_results_H[0]\n",
    "for c in range(1,7): # For Hetero dataframe\n",
    "    print(\"\\tClass\", c)\n",
    "    \n",
    "    print(\"\\t\\tPercentage err to LB\")\n",
    "    eps_avg = eps.loc[str(c)][algs].mean()\n",
    "    eps_avg.sort_values(ascending=True, inplace=True)\n",
    "    print(eps_avg.head(10))\n",
    "    \n",
    "    #print(\"\\t\\tAvg. diff to best\")\n",
    "    #diff_best_avg = diff_best.loc[str(c)][algs].mean()\n",
    "    #diff_best_avg.sort_values(ascending=True, inplace=True)\n",
    "    #print(diff_best_avg.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57462fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "algs = alg_names_unit\n",
    "\n",
    "eps = unit_results_T[0]\n",
    "for c in ['C', 'F']: # For Triplet dataframe\n",
    "    print(\"\\tClass\", c)\n",
    "    \n",
    "    print(\"\\t\\tPercentage err to LB\")\n",
    "    eps_avg = eps.loc[str(c)][algs].mean()\n",
    "    eps_avg.sort_values(ascending=True, inplace=True)\n",
    "    print(eps_avg.head(10))\n",
    "    \n",
    "    #print(\"\\t\\tAvg. diff to best\")\n",
    "    #diff_best_avg = diff_best.loc[str(c)][algs].mean()\n",
    "    #diff_best_avg.sort_values(ascending=True, inplace=True)\n",
    "    #print(diff_best_avg.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5b4b7",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc42f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_small_colors(n):\n",
    "    cmap = cm.get_cmap('nipy_spectral')\n",
    "    #cmap = cm.get_cmap('turbo')\n",
    "    if n > 1:\n",
    "        c = []\n",
    "        for i in range(n):\n",
    "            c.append(cmap(float(i/(n-1))))\n",
    "        #shuffle(c)\n",
    "    else:\n",
    "        c = [cmap(0)]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eafa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKS = ['o', 'v', 'd', '*', '^', 'X']\n",
    "\n",
    "def create_markers(n):\n",
    "    m = len(MARKS)\n",
    "    return [MARKS[i%m] for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e93b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_family_dict(fam_dict):\n",
    "    new_dict = defaultdict(list)\n",
    "    \n",
    "    for fam, fam_list in fam_dict.items():\n",
    "        sp = fam.split(\"-\")\n",
    "        s = sp[0]\n",
    "        if len(sp) > 1 and sp[1].startswith('T'):\n",
    "            s+= \"-\" + sp[1]\n",
    "        \n",
    "        if len(sp) > 1 and sp[0] == \"MB\":\n",
    "            s+= \"-\" + sp[1]\n",
    "        \n",
    "        new_dict[s].extend(fam_list)\n",
    "        \n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808f4cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summary_family(x_data, y_data, alg_list,\n",
    "                 stitle, xlabel, ylabel,\n",
    "                 **kwargs):\n",
    "    \n",
    "    # kwargs parameters\n",
    "    if \"bbox_anchor\" in kwargs:\n",
    "        bbox_anchor = kwargs[\"bbox_anchor\"]\n",
    "    else:\n",
    "        bbox_anchor = (kwargs.get(\"bbox_anchor_x\", 0.5), kwargs.get(\"bbox_anchor_y\", -0.1))\n",
    "    \n",
    "    ncols = kwargs.get(\"ncols\", 5)\n",
    "\n",
    "    x = x_data[alg_list].mean()\n",
    "    y = y_data[alg_list].mean()\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    \n",
    "    # To sort the algos by FFD, BFD, WFD, BCS, MB order\n",
    "    alg_list.sort(key=lambda x: get_score(x))\n",
    "    \n",
    "    fam_dict = create_family_dict(alg_list)\n",
    "    if kwargs.get(\"simplify_dict\", True):\n",
    "        fam_dict = simplify_family_dict(fam_dict)\n",
    "    \n",
    "    marker_list = create_markers(len(alg_list))\n",
    "    color_list = create_small_colors(len(fam_dict))\n",
    "    seed(SEED_NUMBER)\n",
    "    shuffle(color_list)\n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "    legend_markers = []\n",
    "    legend_names = []\n",
    "    for fam, fam_list in fam_dict.items():\n",
    "        n_algos = len(fam_list)\n",
    "        \n",
    "        for alg in fam_list:\n",
    "            plt.scatter(x[alg], y[alg], color=color_list[i], marker=marker_list[j], s=100)\n",
    "            legend_markers.append(plt.Line2D([0,0],[0,0],color=color_list[i], marker=marker_list[j], linestyle=''))\n",
    "            legend_names.append(alg)\n",
    "            j+=1\n",
    "        i+=1\n",
    "        \n",
    "    plt.title(stitle, fontsize=FONT_SIZE+4)\n",
    "    plt.xlabel(xlabel, fontsize=FONT_SIZE+4)\n",
    "    plt.ylabel(ylabel, fontsize=FONT_SIZE+4)\n",
    "    plt.xticks(fontsize=FONT_SIZE)\n",
    "    plt.yticks(fontsize=FONT_SIZE)\n",
    "    \n",
    "    if kwargs.get(\"show_legend\", True):\n",
    "        legend_size = kwargs.get(\"legend_size\", FONT_SIZE-5)\n",
    "        fig.legend(legend_markers, legend_names, numpoints=1, loc='lower center',\n",
    "                   fontsize=legend_size, ncol=ncols, bbox_to_anchor=bbox_anchor)\n",
    "    \n",
    "    if kwargs.get(\"log_scale\", False):\n",
    "        plt.xscale('log')\n",
    "    plt.show()\n",
    "    \n",
    "    filename = kwargs.get(\"filename\", None)\n",
    "    if filename:\n",
    "        fig.savefig(filename, bbox_inches='tight')\n",
    "    #return plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f59152",
   "metadata": {},
   "source": [
    "## Plot for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9256165",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(1,10):\n",
    "    fname = proj_path / f\"plots/all_classes/unit_P{c}.pdf\"\n",
    "    plot_summary_family(unit_results_P[1].loc[str(c)], unit_results_P[0].loc[str(c)], alg_names_unit,\n",
    "            f\"Panigrahy class {c}\", \"Average running time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            bbox_anchor_y=-0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e029764",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(1,7):\n",
    "    fname = proj_path / f\"plots/all_classes/unit_H{c}.pdf\"\n",
    "    plot_summary_family(unit_results_H[1].loc[str(c)], unit_results_H[0].loc[str(c)], alg_names_unit,\n",
    "            f\"Hetero class {c}\", \"Average running time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            simplify_dict=False,\n",
    "            bbox_anchor_y=-0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681acdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"C\", \"F\"]:\n",
    "    fname = proj_path / f\"plots/all_classes/unit_T{c}.pdf\"\n",
    "    plot_summary_family(unit_results_T[1].loc[str(c)], unit_results_T[0].loc[str(c)], alg_names_unit,\n",
    "            f\"Triplet class {c}\", \"Average running time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            simplify_dict=False,\n",
    "            bbox_anchor_y=-0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e56f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce07e0fc",
   "metadata": {},
   "source": [
    "## Plot selected classes only\n",
    "### Class P5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2b2c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxP5 = unit_results_P[0].loc[\"5\"][alg_names_unit].mean().sort_values().head(15).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d615a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_results_P[0].loc[\"5\"][idxP5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c8b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_results_P[1].loc[\"5\",500,:][idxP5].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67775d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_unit_P5 = alg_names_unit.copy()\n",
    "alg_unit_P5.remove('BCS-TFSum-Unit') # Removed because greatly outperformed by all others\n",
    "fname = proj_path / \"plots/algos_unit_P5.pdf\"\n",
    "plot_summary_family(unit_results_P[1].loc[\"5\"], unit_results_P[0].loc[\"5\"], alg_unit_P5,\n",
    "            \"\", \"Average running time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            bbox_anchor=(0.3, 0.12), ncols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cd5bb1",
   "metadata": {},
   "source": [
    "### Class P8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00565a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxP8 = unit_results_P[0].loc[\"8\"][alg_names_unit].mean().sort_values().head(15).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2120eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_results_P[0].loc[\"8\"][idxP8].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5443b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_results_P[1].loc[\"8\",500,:][idxP8].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c28f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = proj_path / \"plots/algos_unit_P8.pdf\"\n",
    "plot_summary_family(unit_results_P[1].loc[\"8\"], unit_results_P[0].loc[\"8\"], alg_names_unit,\n",
    "            \"\", \"Average running time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            bbox_anchor=(0.64, 0.64), ncols=3)\n",
    "####### legend VOLUNTARILY out of bound here BUT correctly placed in the output PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31521193",
   "metadata": {},
   "source": [
    "### Class H5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e3948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxH5 = unit_results_H[0].loc[\"5\"][alg_names_unit].mean().sort_values().head(15).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8f5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_results_H[0].loc[\"5\"][idxH5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdfce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_results_H[1].loc[\"5\",500,:][idxH5].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df578903",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = proj_path / \"plots/algos_unit_H5.pdf\"\n",
    "plot_summary_family(unit_results_H[1].loc[\"5\"], unit_results_H[0].loc[\"5\"], alg_names_unit,\n",
    "            \"\", \"Average unning time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            bbox_anchor=(0.58, 0.54), ncols=2)\n",
    "           ####### legend VOLUNTARILY out of bound here BUT correctly placed in the output PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e147418f",
   "metadata": {},
   "source": [
    "### Class TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23663c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxTF = unit_results_T[0].loc[\"F\"][alg_names_unit].mean().sort_values().head(15).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87467a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_results_T[0].loc[\"F\"][idxTF].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f399d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_results_T[1].loc[\"F\",501,:][idxTF].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f78a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = proj_path / \"plots/algos_unit_TF.pdf\"\n",
    "plot_summary_family(unit_results_T[1].loc[\"F\"], unit_results_T[0].loc[\"F\"], alg_names_unit,\n",
    "            \"\", \"Average running time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            bbox_anchor=(0.64, 0.64), ncols=3)\n",
    "####### legend VOLUNTARILY out of bound here BUT correctly placed in the output PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8390cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97c91c35",
   "metadata": {},
   "source": [
    "### Count avg items per bin in a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d78cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "P5 = df_P[df_P['class'] == '5'].index\n",
    "(df_P.iloc[P5]['n'] / df_P.iloc[P5]['LB_or_OPT']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b6d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "P8 = df_P[df_P['class'] == '8'].index\n",
    "(df_P.iloc[P8]['n'] / df_P.iloc[P8]['LB_or_OPT']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab812ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "H5 = df_H[df_H['class'] == '5'].index\n",
    "(df_H.iloc[H5]['n'] / df_H.iloc[H5]['LB_or_OPT']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee53165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "390fdd29",
   "metadata": {},
   "source": [
    "## Compare two algorithms together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61449f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sup(x):\n",
    "    return x[x > 0].count()\n",
    "\n",
    "def my_eq(x):\n",
    "    return x[x == 0].count()\n",
    "\n",
    "def my_low(x):\n",
    "    return x[x < 0].count()\n",
    "\n",
    "def make_diff(df, list1, list2):\n",
    "    a = df[list1]\n",
    "    b = df[list2]\n",
    "    b.columns = a.columns\n",
    "    df_diff = (a - b).agg(['mean', 'std', my_sup, my_eq, my_low])\n",
    "    return df_diff\n",
    "\n",
    "def make_all_diff(list1, list2):\n",
    "    diff_P = make_diff(big_df_P, list1, list2)\n",
    "    diff_H = make_diff(big_df_H, list1, list2)\n",
    "    diff_T = make_diff(big_df_T, list1, list2)\n",
    "    diff_df = pd.concat([diff_P, diff_H, diff_T], axis=1)\n",
    "    diff_df.columns = [\"diff_P\", \"diff_H\", \"diff_T\"]\n",
    "    return diff_df\n",
    "\n",
    "# When comparing algo A with algo B\n",
    "# Mean is negative when algo A is better than B\n",
    "# my_sup counts when sol of A is worse than B\n",
    "# my_low counts when sol of A is better than B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0978de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = make_all_diff([\"FFD-SumSq-Unit\"], [\"BFD-T1-SumSq-Unit\"])\n",
    "df_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c7de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = make_all_diff([\"FFD-SumSq-Unit\"], [\"WFD-T1-SumSqLoad-Unit\"])\n",
    "df_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32748b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = make_all_diff([\"FFD-SumSq-Unit\"], [\"BCS-DP1-Unit\"])\n",
    "df_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2bf938",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = make_all_diff([\"FFD-SumSq-Unit\"], [\"BIM-BS-DP3-Unit\"])\n",
    "df_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8fb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = make_all_diff([\"BCS-DP1-Unit\"], [\"BIM-BS-DP3-Unit\"])\n",
    "df_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedcb2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = make_all_diff([\"BCS-DP1-Unit\"], [\"BCS-NormDP-Unit\"])\n",
    "df_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find instances with identical result for the 4 algos\n",
    "ddf = big_df_P\n",
    "x = ddf[ddf[\"BCS-DP1-Unit\"] == ddf[\"BIM-BS-DP3-Unit\"]].index\n",
    "y = ddf.loc[x][ddf[\"FFD-SumSq-Unit\"].loc[x] == ddf[\"WFD-T1-SumSqLoad-Unit\"].loc[x]].index\n",
    "z = ddf.loc[y][ddf[\"FFD-SumSq-Unit\"].loc[y] == ddf[\"BCS-DP1-Unit\"].loc[y]]\n",
    "z[[\"class\", \"n\", \"d\", \"FFD-SumSq-Unit\", \"WFD-T1-SumSqLoad-Unit\", \"BCS-DP1-Unit\", \"BIM-BS-DP3-Unit\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d182ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many of these instances per class\n",
    "aa = z[[\"class\", \"n\", \"d\", \"FFD-SumSq-Unit\"]].groupby(by=[\"class\", \"n\", \"d\"], as_index=True).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(1,10):\n",
    "    print(\"class\", c)\n",
    "    print(aa.loc[str(c)].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0933f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1855503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b0f53b9",
   "metadata": {},
   "source": [
    "## Check optimal solution found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea95f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_optimal_found(df, benchmark_name, algo_names, full=False):\n",
    "    if benchmark_name == \"P\":\n",
    "        l = range(1,10)\n",
    "    elif benchmark_name == \"H\":\n",
    "        l = range(1,7)\n",
    "    else: # \"T\"\n",
    "        l = [\"C\", \"F\"]\n",
    "        \n",
    "    sum1 = 0\n",
    "    sum2 = 0\n",
    "        \n",
    "    for c in l:\n",
    "        sub_df = df[df['class'] == str(c)]\n",
    "        best_sol = sub_df[algo_names].min(axis=1)\n",
    "        proved_opt = (sub_df[\"LB\"] == best_sol).sum()\n",
    "        found_opt = (sub_df[\"LB_or_OPT\"] == best_sol).sum()\n",
    "        sum1+=proved_opt\n",
    "        sum2+=found_opt\n",
    "        \n",
    "        if full:\n",
    "            print(f\"Class {c}: {proved_opt} proved optimality (sol = LB) over {sub_df.shape[0]} instances\")\n",
    "            print(f\"\\t {found_opt} optimal solution found\")\n",
    "    \n",
    "    print(f\"Total: {sum1} proved optimality over {df.shape[0]} instances\")\n",
    "    print(f\"Total: {sum2} optimal found over {df.shape[0]} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea670b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "centric_unit = [x for x in alg_names_unit if not \"MB-\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db24fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With only the iten-centric and bin-centric algos with Unit weights\n",
    "print(\"--- For Panigrahy instances ---\")\n",
    "print_optimal_found(df_P, \"P\", centric_unit)\n",
    "print(\"\\n--- For Hetero instances ---\")\n",
    "print_optimal_found(df_H, \"H\", centric_unit)\n",
    "print(\"\\n--- For Triplet instances ---\")\n",
    "print_optimal_found(df_T, \"T\", centric_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f2df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With all algos with Unit weights\n",
    "print(\"--- For Panigrahy instances ---\")\n",
    "print_optimal_found(df_P, \"P\", alg_names_unit)\n",
    "print(\"\\n--- For Hetero instances ---\")\n",
    "print_optimal_found(df_H, \"H\", alg_names_unit)\n",
    "print(\"\\n--- For Triplet instances ---\")\n",
    "print_optimal_found(df_T, \"T\", alg_names_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3178662",
   "metadata": {},
   "outputs": [],
   "source": [
    "centric_all = [x for x in all_algos if not \"MB-\" in x]\n",
    "print(len(centric_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442ecadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With only item-centric and bin-centric algos with all weights\n",
    "print(\"--- For Panigrahy instances ---\")\n",
    "print_optimal_found(df_P, \"P\", centric_all)\n",
    "print(\"\\n--- For Hetero instances ---\")\n",
    "print_optimal_found(df_H, \"H\", centric_all)\n",
    "print(\"\\n--- For Triplet instances ---\")\n",
    "print_optimal_found(df_T, \"T\", centric_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1088d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With all algos and all weights\n",
    "print(\"--- For Panigrahy instances ---\")\n",
    "print_optimal_found(df_P, \"P\", all_algos)\n",
    "print(\"\\n--- For Hetero instances ---\")\n",
    "print_optimal_found(df_H, \"H\", all_algos)\n",
    "print(\"\\n--- For Triplet instances ---\")\n",
    "print_optimal_found(df_T, \"T\", all_algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c26997e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f588d30",
   "metadata": {},
   "source": [
    "# Comparison with Avg weight\n",
    "## Only with selected algorithms from Unit weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fd1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_unit = [\n",
    "    \"FFD-L2-Unit\",\n",
    "    \"BFD-T1-L2-Unit\",\n",
    "    \"WFD-T1-L2Load-Unit\",\n",
    "    \"BCS-DP1-Unit\",\n",
    "    \"MB-WFD-L2-Unit\",\n",
    "    \"MB-Pairing-DP3-Unit\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_algos_avg = [\n",
    "    \"FFD-L2-Unit\",\n",
    "    \"FFD-L2-Avg\",\n",
    "    \"FFD-L2-Avg-Dyn\",\n",
    "    \n",
    "    \"BFD-T1-L2-Unit\",\n",
    "    \"BFD-T1-L2-Avg\",\n",
    "    \"BFD-T1-L2-Avg-Dyn\",\n",
    "    \n",
    "    \"WFD-T1-L2Load-Unit\",\n",
    "    \"WFD-T1-L2Load-Avg\",\n",
    "    \"WFD-T1-L2Load-Avg-Dyn\",\n",
    "    \n",
    "    \"BCS-DP1-Unit\",\n",
    "    \"BCS-DP1-Avg\",\n",
    "    \"BCS-DP1-Avg-Dyn\",\n",
    "    \n",
    "    \"MB-WFD-L2-Unit\",\n",
    "    \"MB-WFD-L2-Avg\",\n",
    "    \"MB-WFD-L2-Avg-Dyn\",\n",
    "    \n",
    "    \"MB-Pairing-DP3-Unit\",\n",
    "    \"MB-Pairing-DP3-Avg\",\n",
    "    \"MB-Pairing-DP3-Avg-Dyn\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc64005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing aggregated results once and for all\n",
    "# For all Centric + Multibin algos\n",
    "big_results_P = get_results(df_P, all_algos, ['class', 'n', 'd'], group_as_index=True)\n",
    "big_results_H = get_results(df_H, all_algos, ['class', 'n', 'd'], group_as_index=True)\n",
    "big_results_T = get_results(df_T, all_algos, ['class', 'n', 'd'], group_as_index=True)\n",
    "# results contains: eps, time, diff, diff_best, best, match_LB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ff4acb",
   "metadata": {},
   "source": [
    "## Plots with Avg weights for all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf22f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(1,10):\n",
    "    fname = proj_path / f\"plots/all_classes/avg_P{c}.pdf\"\n",
    "    plot_summary_family(big_results_P[1].loc[str(c)], big_results_P[0].loc[str(c)], selected_algos_avg,\n",
    "            f\"Panigrahy class {c}\", \"Average running time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            bbox_anchor_y=-0.07, ncols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(1,7):\n",
    "    fname = proj_path / f\"plots/all_classes/avg_H{c}.pdf\"\n",
    "    plot_summary_family(big_results_H[1].loc[str(c)], big_results_H[0].loc[str(c)], selected_algos_avg,\n",
    "            f\"Hetero class {c}\", \"Average running time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            bbox_anchor_y=-0.07, ncols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16072463",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"F\", \"C\"]:\n",
    "    fname = proj_path / f\"plots/all_classes/avg_T{c}.pdf\"\n",
    "    plot_summary_family(big_results_T[1].loc[str(c)], big_results_T[0].loc[str(c)], selected_algos_avg,\n",
    "            f\"Triplet class {c}\", \"Average running time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            bbox_anchor_y=-0.07, ncols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa99e5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2fe2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Results averaged over ALL classes  ---\")\n",
    "for alg in selected_unit:\n",
    "    print(alg)\n",
    "    alg_avg = alg.replace(\"Unit\", \"Avg\")\n",
    "    alg_dyn = alg.replace(\"Unit\", \"Avg-Dyn\")\n",
    "    a = big_results_P[0][alg].mean()\n",
    "    b = big_results_P[0][alg_avg].mean()\n",
    "    c = big_results_P[0][alg_dyn].mean()\n",
    "    print(f\"  Unit VS Avg: eps diff {a - b:.2f} % {b / a:.2f}\")\n",
    "    print(f\"  Unit VS Dyn: eps diff {a - c:.2f} % {c / a:.2f}\\n\")\n",
    "    \n",
    "    ta = big_results_P[1][alg].mean()\n",
    "    tb = big_results_P[1][alg_avg].mean()\n",
    "    tc = big_results_P[1][alg_dyn].mean()\n",
    "    print(f\"  Unit VS Avg: time diff {ta - tb:.2f} % {tb / ta:.2f}\")\n",
    "    print(f\"  Unit VS Dyn: time diff {ta - tc:.2f} % {tc / ta:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8b56e7",
   "metadata": {},
   "source": [
    "### Selected class P8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a981031",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_results_P[0].loc['8'][selected_algos_avg].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0009ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_results_P[1].loc['8'][selected_algos_avg].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd197a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_results_P[1].loc['8'][selected_algos_avg].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27519c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = proj_path / \"plots/avg_weights_P8.pdf\"\n",
    "plot_summary_family(big_results_P[1].loc[\"8\"], big_results_P[0].loc[\"8\"], selected_algos_avg,\n",
    "            \"\", \"Running time (ms) - log scale\", \"% error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            bbox_anchor=(0.71, 0.13),\n",
    "            ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430cfc57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6104cff4",
   "metadata": {},
   "source": [
    "# Comparison with all algos and all weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c563a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_meta_algos(df, alg_names):\n",
    "    centric = [x for x in alg_names if not \"MB-\" in x]\n",
    "    \n",
    "    time_cols_centric = [i+'_timems' for i in centric]\n",
    "    df['meta-centric'] = df[centric].min(axis=1)\n",
    "    df['meta-centric_timems'] = df[time_cols_centric].sum(axis=1)\n",
    "    \n",
    "    time_cols_all = [i+'_timems' for i in alg_names]\n",
    "    df['meta-all'] = df[alg_names].min(axis=1)\n",
    "    df['meta-all_timems'] = df[time_cols_all].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169bfbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_meta_algos(df_P, all_algos)\n",
    "add_meta_algos(df_H, all_algos)\n",
    "add_meta_algos(df_T, all_algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "algos_with_meta = all_algos + [\"meta-centric\", \"meta-all\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d46f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing aggregated results once and for all\n",
    "# For all Centric + Multibin algos\n",
    "big_results_P = get_results(df_P, algos_with_meta, ['class', 'n', 'd'], group_as_index=True)\n",
    "big_results_H = get_results(df_H, algos_with_meta, ['class', 'n', 'd'], group_as_index=True)\n",
    "big_results_T = get_results(df_T, algos_with_meta, ['class', 'n', 'd'], group_as_index=True)\n",
    "\n",
    "# results contains: eps, time, diff, diff_best, best, match_LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab382e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = [x for x in all_algos if \"MB-\" not in x and \"BCS\" not in x]\n",
    "bi = [x for x in all_algos if \"BCS\" in x]\n",
    "mb = [x for x in all_algos if \"MB-\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_algos), len(it), len(bi), len(mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5e1e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_P\n",
    "algs = all_algos\n",
    "\n",
    "nb_instances = df.shape[0]\n",
    "sub_list = algs.copy()\n",
    "new_list = []\n",
    "for i in range(len(algs)):\n",
    "    algo_test = sub_list.pop(0)\n",
    "    new_list.append(algo_test)\n",
    "    # Find algos performing equally to algo_test\n",
    "    counts = df[sub_list].apply(lambda x: x == df[algo_test]).sum()\n",
    "    l = list(counts[counts == nb_instances].index)\n",
    "    if (len(l) != 0):\n",
    "        # If some are found, remove them from the sub_list\n",
    "        print(f\"{algo_test} identical to: {l}\")\n",
    "        sub_list = [x for x in sub_list if not x in l]\n",
    "    if (len(sub_list) == 0):\n",
    "        break\n",
    "# Sub_list contains 'unique' algos\n",
    "print(f\"There are {len(new_list)} 'unique' algos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8912d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = ['BCS-NormDP-Avg-Bin', 'MB-Pairing-DP1-UtilRatio',\n",
    "             'MB-Pairing-NormDP-Avg', 'MB-Pairing-NormDP-Avg-Dyn',\n",
    "             'MB-Pairing-DP3-UtilRatio',\n",
    "             'MB-WFD-Linf-UtilRatio',\n",
    "             'MB-WFD-L1-UtilRatio',\n",
    "             'MB-WFD-L2-UtilRatio',\n",
    "             'MB-BFD-L2Load-UtilRatio'\n",
    "            ]\n",
    "new_algos = [x for x in all_algos if not x in to_remove]\n",
    "#new_algos = [x for x in algos_with_meta if not x in to_remove]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d351707",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = [\"BF-\", \"WF-\"] # Need the dash after BF and WF to keep BFD/WFD\n",
    "filtered_algos = filter_algo_list(new_algos, to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b09adb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a48f383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_selected_list(eps, fam_dict, with_meta=False):\n",
    "    l = []\n",
    "    for fam, fam_list in fam_dict.items():\n",
    "        if fam == \"FF\":\n",
    "            l.append(\"FF\")\n",
    "        else:\n",
    "            eps_avg = eps[fam_list].mean()\n",
    "            eps_avg.sort_values(ascending=True, inplace=True)\n",
    "            l.extend(eps_avg.index[:1])\n",
    "    \n",
    "    if with_meta:\n",
    "        l = l + [\"meta-centric\", \"meta-all\"]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2dd965",
   "metadata": {},
   "outputs": [],
   "source": [
    "fam_dict = create_family_dict(filtered_algos)\n",
    "#fam_dict = create_family_dict(new_algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99cff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(1,10):\n",
    "    fname = proj_path / f\"plots/all_classes/all_weights_P{c}.pdf\"\n",
    "    sel_algos = create_selected_list(big_results_P[0].loc[str(c)], fam_dict, with_meta=True)\n",
    "    plot_summary_family(big_results_P[1].loc[str(c)], big_results_P[0].loc[str(c)], sel_algos,\n",
    "            f\"Panigrahy class {c}\", \"Average running time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            simplify_dict=True, show_legend=True,\n",
    "            bbox_anchor=(0.5,-0.15), ncols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9fb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(1,7):\n",
    "    fname = proj_path / f\"plots/all_classes/all_weights_H{c}.pdf\"\n",
    "    sel_algos = create_selected_list(big_results_H[0].loc[str(c)], fam_dict, with_meta=True)\n",
    "    plot_summary_family(big_results_H[1].loc[str(c)], big_results_H[0].loc[str(c)], sel_algos,\n",
    "            f\"Hetero class {c}\", \"Average running time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            simplify_dict=True, show_legend=True,\n",
    "            bbox_anchor=(0.5,-0.15), ncols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d9fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"C\", \"F\"]:\n",
    "    fname = proj_path / f\"plots/all_classes/all_weights_T{c}.pdf\"\n",
    "    sel_algos = create_selected_list(big_results_T[0].loc[str(c)], fam_dict, with_meta=True)\n",
    "    plot_summary_family(big_results_T[1].loc[str(c)], big_results_T[0].loc[str(c)], sel_algos,\n",
    "            f\"Triplet class {c}\", \"Average running time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=None,\n",
    "            simplify_dict=True, show_legend=True,\n",
    "            bbox_anchor=(0.5,-0.15), ncols=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76746ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0980ea8",
   "metadata": {},
   "source": [
    "## Plots of selected classes\n",
    "### Class P5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc229f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_algos_P5 = create_selected_list(big_results_P[0].loc[\"5\"], fam_dict, with_meta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77043a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_P5 = big_results_P[0].loc[\"5\"]\n",
    "time_P5 = big_results_P[1].loc[\"5\",500,:]\n",
    "idx_P5 = eps_P5[sel_algos_P5].mean().sort_values().index\n",
    "for alg in idx_P5:\n",
    "    print(f\"{alg}\\n\\teps: {eps_P5[alg].mean():.2f}\\n\\ttime: {time_P5[alg].mean():.2f}\\t{time_P5[alg].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b05cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = proj_path / \"plots/all_weights_P5.pdf\"\n",
    "plot_summary_family(big_results_P[1].loc[\"5\"], big_results_P[0].loc[\"5\"], sel_algos_P5,\n",
    "            \"\", \"Average running time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            simplify_dict=True, show_legend=True,\n",
    "            ncols = 2, bbox_anchor=(0.70, 0.57),\n",
    "            legend_size=FONT_SIZE-6\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab3b585",
   "metadata": {},
   "source": [
    "### Class P8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113c86cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_algos_P8 = create_selected_list(big_results_P[0].loc[\"8\"], fam_dict, with_meta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14adf19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_P8 = big_results_P[0].loc[\"8\"]\n",
    "time_P8 = big_results_P[1].loc[\"8\",500,:]\n",
    "idx_P8 = eps_P8[sel_algos_P8].mean().sort_values().index\n",
    "for alg in idx_P8:\n",
    "    print(f\"{alg}\\n\\teps: {eps_P8[alg].mean():.2f}\\n\\ttime: {time_P8[alg].mean():.2f}\\t{time_P8[alg].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d176ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = proj_path / \"plots/all_weights_P8.pdf\"\n",
    "plot_summary_family(big_results_P[1].loc[\"8\"], big_results_P[0].loc[\"8\"], sel_algos_P8,\n",
    "            \"\", \"Average running time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            simplify_dict=True, show_legend=True,\n",
    "            ncols = 2, bbox_anchor=(0.675, 0.54)\n",
    "        ####### legend VOLUNTARILY out of bound here BUT correctly placed in the output PDF\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c73cb",
   "metadata": {},
   "source": [
    "### class H5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c53594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_algos_H5 = create_selected_list(big_results_H[0].loc[\"5\"], fam_dict, with_meta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbdef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_H5 = big_results_H[0].loc[\"5\"]\n",
    "time_H5 = big_results_H[1].loc[\"5\",500,:]\n",
    "idx_H5 = eps_H5[sel_algos_H5].mean().sort_values().index\n",
    "for alg in idx_H5:\n",
    "    print(f\"{alg}\\n\\teps: {eps_H5[alg].mean():.2f}\\n\\ttime: {time_H5[alg].mean():.2f}\\t{time_H5[alg].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d0f187",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = proj_path / \"plots/all_weights_H5.pdf\"\n",
    "plot_summary_family(big_results_H[1].loc[\"5\"], big_results_H[0].loc[\"5\"], sel_algos_H5,\n",
    "            \"\", \"Average running time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            simplify_dict=True, show_legend=True,\n",
    "            ncols = 2, bbox_anchor=(0.67, 0.54)\n",
    "            ####### legend VOLUNTARILY out of bound here BUT correctly placed in the output PDF\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f5f343",
   "metadata": {},
   "source": [
    "### class TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbefe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_algos_TF = create_selected_list(big_results_T[0].loc[\"F\"], fam_dict, with_meta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb400ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_TF = big_results_T[0].loc[\"F\"]\n",
    "time_TF = big_results_T[1].loc[\"F\",501,:]\n",
    "idx_TF = eps_TF[sel_algos_TF].mean().sort_values().index\n",
    "for alg in idx_TF:\n",
    "    print(f\"{alg}\\n\\teps: {eps_TF[alg].mean():.2f}\\n\\ttime: {time_TF[alg].mean():.2f}\\t{time_TF[alg].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285470b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = proj_path / \"plots/all_weights_TF.pdf\"\n",
    "plot_summary_family(big_results_T[1].loc[\"F\"], big_results_T[0].loc[\"F\"], sel_algos_TF,\n",
    "            \"\", \"Average running time (ms) - log scale\", \"Average % error to LB\",\n",
    "            log_scale=True, filename=fname,\n",
    "            simplify_dict=True, show_legend=True,\n",
    "            #ncols = 2, bbox_anchor=(0.68, 0.52)\n",
    "            ncols = 2, bbox_anchor=(0.34, 0.13)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57812567",
   "metadata": {},
   "source": [
    "## Check optimal found with all algos and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad41f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- For Panigrahy instances ---\")\n",
    "print_optimal_found(df_P, \"P\", all_algos)\n",
    "print(\"\\n--- For Hetero instances ---\")\n",
    "print_optimal_found(df_H, \"H\", all_algos)\n",
    "print(\"\\n--- For Triplet instances ---\")\n",
    "print_optimal_found(df_T, \"T\", all_algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9125730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "centric_algos = [x for x in all_algos if \"MB-\" not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ec8eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- For Panigrahy instances ---\")\n",
    "print_optimal_found(df_P, \"P\", centric_algos)\n",
    "print(\"\\n--- For Hetero instances ---\")\n",
    "print_optimal_found(df_H, \"H\", centric_algos)\n",
    "print(\"\\n--- For Triplet instances ---\")\n",
    "print_optimal_found(df_T, \"T\", centric_algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9baaac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e17eb5ad",
   "metadata": {},
   "source": [
    "## Plots error as function of n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe08e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_n_eps(x_data, y_data, c, alg_list,\n",
    "               stitle, xlabel, ylabel,\n",
    "               **kwargs):\n",
    "    \n",
    "    # kwargs parameters\n",
    "    if \"bbox_anchor\" in kwargs:\n",
    "        bbox_anchor = kwargs[\"bbox_anchor\"]\n",
    "    else:\n",
    "        bbox_anchor = (kwargs.get(\"bbox_anchor_x\", 0.5), kwargs.get(\"bbox_anchor_y\", -0.12))\n",
    "    \n",
    "    ncols = kwargs.get(\"ncols\", 5)\n",
    "    \n",
    "    #fig, (ax1, ax2, ax3) = plt.subplots(3, sharex=True, sharey=True)\n",
    "    fig = plt.figure(figsize=(15,8))\n",
    "    gs = fig.add_gridspec(3, 1)\n",
    "    (ax1, ax2, ax3) = gs.subplots(sharex=True, sharey=True)\n",
    "    \n",
    "    # To sort the algos by FFD, BFD, WFD, BCS, MB order\n",
    "    alg_list.sort(key=lambda x: get_score(x))\n",
    "    \n",
    "    #fam_colors = family_color_dict\n",
    "    #color_list = create_alg_colors(alg_list, fam_colors, family_list)\n",
    "    color_list = create_small_colors(len(alg_list))\n",
    "    seed(SEED_NUMBER+1)\n",
    "    shuffle(color_list)\n",
    "    \n",
    "    y1 = y_data.loc[c, :, 3]\n",
    "    y2 = y_data.loc[c, :, 5]\n",
    "    y3 = y_data.loc[c, :, 10]\n",
    "\n",
    "    for i in range(len(alg_list)):\n",
    "        alg = alg_list[i]\n",
    "        #plt.plot(x_data, y_data[alg], '.:', c=color_list[i], label=alg, linewidth=2, markersize=15)\n",
    "        ax1.plot(x_data, y1[alg], '.:', c=color_list[i], label=alg, linewidth=2, markersize=15)\n",
    "        ax2.plot(x_data, y2[alg], '.:', c=color_list[i], label=alg, linewidth=2, markersize=15)\n",
    "        ax3.plot(x_data, y3[alg], '.:', c=color_list[i], label=alg, linewidth=2, markersize=15)\n",
    "\n",
    "    #plt.legend(numpoints=1, loc='lower center', ncol=4, bbox_to_anchor=(.5, -.3))\n",
    "    \n",
    "    #simple_names = [dict_simple_names.get(x,x) for x in alg_list]\n",
    "    markers = [plt.Line2D([0,0],[0,0],color=color, marker='o', linestyle='') for color in color_list]\n",
    "    fig.legend(markers, alg_list, numpoints=1, loc='lower center', fontsize=FONT_SIZE-4,\n",
    "               ncol=ncols, bbox_to_anchor=bbox_anchor)\n",
    "\n",
    "    plt.xticks(x_data)\n",
    "    #fig.suptitle(stitle, fontsize=FONT_SIZE)\n",
    "    plt.xlabel(xlabel, fontsize=FONT_SIZE)\n",
    "    #plt.ylabel(ylabel, fontsize=FONT_SIZE)\n",
    "    ax2.set_ylabel(ylabel, fontsize=FONT_SIZE+3)\n",
    "    \n",
    "    ax1.set_title(stitle + \", d=3\", fontsize=FONT_SIZE)\n",
    "    ax2.set_title(\"d=5\", fontsize=FONT_SIZE-2)\n",
    "    ax3.set_title(\"d=10\", fontsize=FONT_SIZE-2)\n",
    "    \n",
    "    ax1.tick_params(axis=\"y\", labelsize=FONT_SIZE-3)\n",
    "    ax2.tick_params(axis=\"y\", labelsize=FONT_SIZE-3)\n",
    "    ax3.tick_params(axis=\"both\", labelsize=FONT_SIZE-3)\n",
    "    \n",
    "    if kwargs.get(\"log_scale_x\", False):\n",
    "        plt.xscale('log')\n",
    "    if kwargs.get(\"log_scale_y\", False):\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    filename = kwargs.get(\"filename\", None)\n",
    "    if filename:\n",
    "        fig.savefig(filename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631bb12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_fam_dict = create_simple_family_dict(filtered_algos)\n",
    "del simple_fam_dict[\"FF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4086405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(1,10):\n",
    "    fname = proj_path / f\"plots/all_lines/lines_P{c}.pdf\"\n",
    "    sel_algos_test = create_selected_list(big_results_P[0].loc[str(c)], simple_fam_dict, with_meta=False)\n",
    "    plot_n_eps([20, 40, 60, 120, 250, 500], big_results_P[0], str(c), sel_algos_test,\n",
    "           f\"Class {c} of Panigrahy\", \"Number of items\", \"% error\",\n",
    "           ncols=3, bbox_anchor=(0.5, -0.04), filename=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aadbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(1,7):\n",
    "    fname = proj_path / f\"plots/all_lines/lines_H{c}.pdf\"\n",
    "    sel_algos_test = create_selected_list(big_results_H[0].loc[str(c)], simple_fam_dict, with_meta=False)\n",
    "    plot_n_eps([20, 40, 60, 120, 250, 500], big_results_H[0], str(c), sel_algos_test,\n",
    "           f\"Class {c} of Hetero\", \"Number of items\", \"% error\",\n",
    "           ncols=3, bbox_anchor=(0.5, -0.04), filename=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c0003",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"F\", \"C\"]:\n",
    "    fname = proj_path / f\"plots/all_lines/lines_T{c}.pdf\"\n",
    "    sel_algos_test = create_selected_list(big_results_T[0].loc[str(c)], simple_fam_dict, with_meta=False)\n",
    "    plot_n_eps([60, 120, 249, 501], big_results_T[0], str(c), sel_algos_test,\n",
    "           f\"Class {c} of Triplet\", \"Number of items\", \"% error\",\n",
    "           ncols=3, bbox_anchor=(0.5, -0.04), filename=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a50edfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7ffdd58",
   "metadata": {},
   "source": [
    "# Compare several algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30d67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sup(x):\n",
    "    return x[x > 0].count()\n",
    "\n",
    "def my_eq(x):\n",
    "    return x[x == 0].count()\n",
    "\n",
    "def my_low(x):\n",
    "    return x[x < 0].count()\n",
    "\n",
    "def make_diff(df, list1, list2):\n",
    "    a = df[list1]\n",
    "    b = df[list2]\n",
    "    b.columns = a.columns\n",
    "    df_diff = (a - b).agg(['mean', 'std', my_sup, my_eq, my_low])\n",
    "    return df_diff\n",
    "\n",
    "def make_diff_classes(algo1, algo2, base_df, bench_name):\n",
    "    if bench_name == \"P\":\n",
    "        l = range(1,10)\n",
    "    elif bench_name == \"H\":\n",
    "        l = range(1,7)\n",
    "    else:\n",
    "        l = [\"C\", \"F\"]\n",
    "        \n",
    "    dfs = []\n",
    "    cols = []\n",
    "    for c in l:\n",
    "        dfs.append(make_diff(base_df[base_df[\"class\"] ==str(c)], [algo1], [algo2]))\n",
    "        cols.append(f\"{algo1}_{c}\")\n",
    "    \n",
    "    diff_df = pd.concat(dfs, axis=1)\n",
    "    diff_df.columns = cols\n",
    "    return diff_df\n",
    "\n",
    "# When comparing algo A with algo B\n",
    "# Mean is negative when algo A is better than B\n",
    "# my_sup counts when sol of A is worse than B\n",
    "# my_low counts when sol of A is better than B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20277148",
   "metadata": {},
   "outputs": [],
   "source": [
    "alA = \"FFD-Sum-Avg\"\n",
    "alB = \"FFD-SumSq-Avg\"\n",
    "df_diff = make_diff_classes(alA, alB, big_df_P, \"P\")\n",
    "print(df_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a67feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = make_diff_classes(alA, alB, big_df_H, \"H\")\n",
    "print(df_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcffa518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870dd415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = make_diff_classes(\"BCS-DP1-Expo\", \"BCS-DP2-Avg-Dyn\", big_df_P, \"P\")\n",
    "print(df_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = make_diff_classes(\"BIM-BS-DP3-Avg\", \"BIM-BS-DP1-DivAvg-Dyn\", big_df_T, \"T\")\n",
    "print(df_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d933fa27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = make_diff_classes(\"FFD-Sum-Avg-Dyn\", \"WFD-T1-SumSqLoad-Avg-Dyn\", big_df_P, \"P\")\n",
    "print(df_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43bd527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b821243c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = make_diff(big_df_P, [\"FFD-SumSq-Unit\", \"FFD-Sum-Unit\"],[\"FFD-SumSq-Avg\", \"FFD-Sum-Avg\"])\n",
    "print(df_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a30419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = make_all_diff([\"FFD-SumSq-Unit\", \"FFD-Sum-Unit\"],\n",
    "                        [\"FFD-SumSq-Avg\", \"FFD-Sum-Avg\"])\n",
    "df_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081c427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = make_all_diff([\"FFD-SumSq-Unit\"],\n",
    "                        [\"FFD-SumSq-Avg\"])\n",
    "df_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b355b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae5da5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6140adc8",
   "metadata": {},
   "source": [
    "## For Latex tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce14d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_df(main_df, results, alg_names):\n",
    "    sub_df = main_df[['class', 'n', 'd', 'best_sol']].copy()\n",
    "    sub_df[\"best_opt\"] = sub_df[\"best_sol\"] == main_df[\"LB_or_OPT\"]\n",
    "    sub_df[\"best_eps\"] = round(sub_df[\"best_sol\"] / main_df[\"LB_or_OPT\"] - 1, 3)*100\n",
    "\n",
    "    avg_best = sub_df[['class', 'n', 'd', 'best_sol']].groupby(by=['class', 'n', 'd'], as_index=True).mean()\n",
    "    opt_best = sub_df[['class', 'n', 'd', 'best_opt']].groupby(by=['class', 'n', 'd'], as_index=True).sum()\n",
    "    eps_best = sub_df[['class', 'n', 'd', 'best_eps']].groupby(by=['class', 'n', 'd'], as_index=True).mean()\n",
    "\n",
    "    eps, time, _, diff_best, _, match_LB = results\n",
    "    time_best = time.sum(axis=1) # The cumulated time taken by all algorithms\n",
    "    list_df = [avg_best, opt_best, eps_best, time_best]\n",
    "    cols = [\"avg_best\", \"opt_best\", \"eps_best\", \"time_best\"]\n",
    "    for alg in alg_names:\n",
    "        list_df.append(eps[alg])\n",
    "        list_df.append(diff_best[alg])\n",
    "        list_df.append(match_LB[alg])\n",
    "        list_df.append(time[alg])\n",
    "        cols.extend([alg+\"_eps\", alg+\"_diff\", alg+\"_opt\", alg+\"_time\"])\n",
    "        \n",
    "    res_df = pd.concat(list_df, axis=1)\n",
    "    res_df.columns = cols\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e3e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_path = proj_path / \"results/tables\"\n",
    "print(table_path)\n",
    "\n",
    "def write_table(filename, s):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d449802",
   "metadata": {},
   "source": [
    "### Tables for Unit weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2029eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_name_unit(alg_name):\n",
    "    v = alg_name.split('-')\n",
    "    if len(v) < 2:\n",
    "        return alg_name\n",
    "    \n",
    "    if 'T1' in alg_name or 'BS' in alg_name:\n",
    "        return f\"{v[0]}-{v[2]}\"\n",
    "    \n",
    "    return f\"{v[0]}-{v[1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_table_unit(df, algo_list, class_range, n_range,\n",
    "                       stitle, slabel):\n",
    "    shead = \"\\\\begin{landscape}\\n\\\\begin{table}\\n\\\\footnotesize\\n\\\\centering\\n\\\\caption{\" + stitle + \"}\"\n",
    "    shead+= \"\\label{\" + slabel + \"}\\n\"\n",
    "    shead+= \"\\\\begin{tabular}{|lrrr|rrr|\" + \"rrr|\"*(len(algo_list)) + \"}\\n\"\n",
    "    shead+= \"\\\\hline\\n\"\n",
    "    shead+= \" & & & & \\multicolumn{3}{c|}{Combined best}\"\n",
    "    salgs = \"\\\\rule{0pt}{.4cm}Class & n & d & Avg.Bins & \\%err & Time & \\#opt\"\n",
    "    for alg in algo_list:\n",
    "        shead+= \" & \\multicolumn{3}{c|}{\" + simple_name_unit(alg) + \"}\"\n",
    "        salgs += \" & \\%err & Diff & Time\"\n",
    "    shead+= \"\\\\\\\\\\n\" + salgs + \"\\\\\\\\\\n\\hline\\n\"\n",
    "\n",
    "    sbody = \"\"\n",
    "    for c in class_range:\n",
    "        cfirst = str(c)\n",
    "        sbody+= cfirst\n",
    "        for n in n_range:\n",
    "            sbody+= \"\\\\rule{0pt}{.6cm} & \" + str(n)\n",
    "            smid = \" &\"\n",
    "            for d in [3, 5, 10]:\n",
    "                avg_best = df.loc[cfirst,n,d]['avg_best']\n",
    "                eps_best = df.loc[cfirst,n,d]['eps_best']\n",
    "                opt_best = df.loc[cfirst,n,d]['opt_best']\n",
    "                time_best = df.loc[cfirst,n,d]['time_best']\n",
    "                smid+= f\" {d} & {avg_best:.1f} & {eps_best:.1f} & {time_best:.1f} & {opt_best:.0f}\"\n",
    "                for alg in algo_list:\n",
    "                    smid+= f\" & {df.loc[cfirst,n,d][alg+'_eps']:.1f} & {df.loc[cfirst,n,d][alg+'_diff']:.1f}\"\n",
    "                    smid+= f\" & {df.loc[cfirst,n,d][alg+'_time']:.1f}\"\n",
    "                sbody+= smid + \"\\\\\\\\\\n\"\n",
    "                smid = \" & &\"\n",
    "\n",
    "        sbody+= \"\\multicolumn{4}{|c|}{\\\\rule{0pt}{.5cm}Summary over all instances}\"\n",
    "        sbody+= f\" & {df.loc[cfirst]['eps_best'].mean():.1f} & {df.loc[cfirst]['time_best'].mean():.1f}\"\n",
    "        sbody+= f\" & {df.loc[cfirst]['opt_best'].sum():.0f}\"\n",
    "        for alg in algo_list:\n",
    "            sbody+= f\" & {df.loc[cfirst][alg+'_eps'].mean():.1f} & {df.loc[cfirst][alg+'_diff'].mean():.1f}\"\n",
    "            sbody+= f\" & {df.loc[cfirst][alg+'_time'].mean():.1f}\"\n",
    "        sbody+= \"\\\\\\\\\\n\" + \"\\\\hline\\n\"\n",
    "        \n",
    "    sfull = shead + sbody + \"\\end{tabular}\\n\\end{table}\\n\\end{landscape}\"\n",
    "    \n",
    "    return sfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d66cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df_P = create_table_df(big_df_P, big_results_P, all_algos)\n",
    "table_df_H = create_table_df(big_df_H, big_results_H, all_algos)\n",
    "table_df_T = create_table_df(big_df_T, big_results_T, all_algos)\n",
    "#table_df_Q = create_table_df(big_df_Q, big_results_Q, all_algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa6cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panigrahy instances\n",
    "s1 = generate_table_unit(table_df_P,\n",
    "        [\"FFD-Max-Unit\", \"FFD-Sum-Unit\", \"FFD-SumSq-Unit\", \"BCS-DP1-Unit\", \"BIM-BS-DP3-Unit\"],\n",
    "        [1, 2, 3],\n",
    "        [20, 120, 500],\n",
    "        #[20, 40, 60, 120, 250, 500],\n",
    "        \"Unit weights - Panigrahy instances\", \"tab:unit-P11\")\n",
    "write_table(table_path / \"unit-P11.tex\", s1)\n",
    "\n",
    "\n",
    "###\n",
    "s2 = generate_table_unit(table_df_P,\n",
    "        [\"FFD-Max-Unit\", \"FFD-Sum-Unit\", \"FFD-SumSq-Unit\", \"BCS-DP1-Unit\", \"BIM-BS-DP3-Unit\"],\n",
    "        [4, 5, 6],\n",
    "        [20, 120, 500],\n",
    "        #[20, 40, 60, 120, 250, 500],\n",
    "        \"Unit weights - Panigrahy instances\", \"tab:unit-P21\")\n",
    "write_table(table_path / \"unit-P21.tex\", s2)\n",
    "\n",
    "\n",
    "###\n",
    "s3 = generate_table_unit(table_df_P,\n",
    "        [\"FFD-Max-Unit\", \"FFD-Sum-Unit\", \"FFD-SumSq-Unit\", \"BCS-DP1-Unit\", \"BIM-BS-DP3-Unit\"],\n",
    "        [7, 8, 9],\n",
    "        [20, 120, 500],\n",
    "        #[20, 40, 60, 120, 250, 500],\n",
    "        \"Unit weights - Panigrahy instances\", \"tab:unit-P31\")\n",
    "write_table(table_path / \"unit-P31.tex\", s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba7f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hetero instances\n",
    "s1 = generate_table_unit(table_df_H,\n",
    "        [\"FFD-Max-Unit\", \"FFD-Sum-Unit\", \"FFD-SumSq-Unit\", \"BCS-DP1-Unit\", \"BIM-BS-DP3-Unit\"],\n",
    "        [1, 2, 3],\n",
    "        [20, 120, 500],\n",
    "        #[20, 40, 60, 120, 250, 500],\n",
    "        \"Unit weights - Hetero instances\", \"tab:unit-H11\")\n",
    "write_table(table_path / \"unit-H11.tex\", s1)\n",
    "\n",
    "s2 = generate_table_unit(table_df_H,\n",
    "        [\"FFD-Max-Unit\", \"FFD-Sum-Unit\", \"FFD-SumSq-Unit\", \"BCS-DP1-Unit\", \"BIM-BS-DP3-Unit\"],\n",
    "        [4, 5, 6],\n",
    "        [20, 120, 500],\n",
    "        #[20, 40, 60, 120, 250, 500],\n",
    "        \"Unit weights - Hetero instances\", \"tab:unit-H21\")\n",
    "write_table(table_path / \"unit-H21.tex\", s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd6c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triplet instances\n",
    "s1 = generate_table_unit(table_df_T,\n",
    "        [\"FFD-Max-Unit\", \"FFD-Sum-Unit\", \"FFD-SumSq-Unit\", \"BCS-DP1-Unit\", \"BIM-BS-DP3-Unit\"],\n",
    "        ['C', 'F'],\n",
    "        [60, 120, 249, 501],\n",
    "        \"Unit weights - Triplet instances\", \"tab:unit-T11\")\n",
    "write_table(table_path / \"unit-T11.tex\", s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3578b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4a72d4",
   "metadata": {},
   "source": [
    "### Generate summary table with average over all n and d for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b97b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_table_unit_average(df, algo_list, class_range,\n",
    "                       stitle, slabel):\n",
    "    shead = \"\\\\begin{landscape}\\n\\\\begin{table}\\n\\\\footnotesize\\n\\\\centering\\n\\\\caption{\" + stitle + \"}\"\n",
    "    shead+= \"\\label{\" + slabel + \"}\\n\"\n",
    "    shead+= \"\\\\begin{tabular}{|lr|rrr|\" + \"rrr|\"*(len(algo_list)) + \"}\\n\"\n",
    "    shead+= \"\\\\hline\\n\"\n",
    "    shead+= \" & & \\multicolumn{3}{c|}{Combined best}\"\n",
    "    salgs = \"\\multicolumn{2}{|l|}{Class} & \\%err & Time & \\#opt\"\n",
    "    for alg in algo_list:\n",
    "        shead+= \" & \\multicolumn{3}{c|}{\" + simple_name_unit(alg) + \"}\"\n",
    "        salgs += \" & \\%err & Diff & Time\"\n",
    "    shead+= \"\\\\\\\\\\n\" + salgs + \"\\\\\\\\\\n\\hline\\n\"\n",
    "\n",
    "    sbody = \"Panigrahy\"\n",
    "    for c in class_range:\n",
    "        cfirst = str(c)\n",
    "        \n",
    "        sbody+= \"\\\\rule{0pt}{.5cm} & \" + cfirst\n",
    "        sbody+= f\" & {df.loc[cfirst]['eps_best'].mean():.1f} & {df.loc[cfirst]['time_best'].mean():.1f}\"\n",
    "        sbody+= f\" & {df.loc[cfirst]['opt_best'].sum():.0f}\"\n",
    "        for alg in algo_list:\n",
    "            sbody+= f\" & {df.loc[cfirst][alg+'_eps'].mean():.1f} & {df.loc[cfirst][alg+'_diff'].mean():.1f}\"\n",
    "            sbody+= f\" & {df.loc[cfirst][alg+'_time'].mean():.1f}\"\n",
    "        sbody+= \"\\\\\\\\\\n\"\n",
    "        \n",
    "    \n",
    "        \n",
    "    sfull = shead + sbody + \"\\\\hline\\n\\end{tabular}\\n\\end{table}\\n\\end{landscape}\"\n",
    "    \n",
    "    return sfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2b80fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panigrahy instances\n",
    "s1 = generate_table_unit_average(table_df_P,\n",
    "        [\"FFD-SumSq-Unit\", \"WFD-T1-SumSqLoad-Unit\", \"BCS-DP1-Unit\", \"BIM-BS-DP3-Unit\"],\n",
    "        range(1,10),\n",
    "        \"Unit weights - Panigrahy instances\", \"tab:summary-unit-P\")\n",
    "write_table(table_path / \"summary-unit-P.tex\", s1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ef13a3",
   "metadata": {},
   "source": [
    "## Generate Latex tables for comparing Avg weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df_P = create_table_df(big_df_P, big_results_P, all_algos)\n",
    "table_df_H = create_table_df(big_df_H, big_results_H, all_algos)\n",
    "table_df_T = create_table_df(big_df_T, big_results_T, all_algos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe0ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_algo_shortnames(alg_name):\n",
    "    s = alg_name.split('-')\n",
    "    if 'T1' in alg_name or 'BS' in alg_name:\n",
    "        s.pop(1)\n",
    "    a1 = '-'.join(s)\n",
    "    a2 = \"/-Avg\"\n",
    "    a3 = \"/-Avg-Dyn\"\n",
    "    return [a1, a2, a3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fd9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_algo_names(alg_name):\n",
    "    s = alg_name.split('-')\n",
    "    a1 = '-'.join(s)\n",
    "    s[-1] = \"Avg\"\n",
    "    a2 = '-'.join(s)\n",
    "    s.append(\"Dyn\")\n",
    "    a3 = '-'.join(s)\n",
    "    return [a1, a2, a3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a05eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_table_avg(df, algo_list, class_range, n_range,\n",
    "                       stitle, slabel):\n",
    "    shead = \"\\\\begin{landscape}\\n\\\\begin{table}\\n\\\\footnotesize\\n\\\\centering\\n\\\\caption{\" + stitle + \"}\"\n",
    "    shead+= \"\\label{\" + slabel + \"}\\n\"\n",
    "    shead+= \"\\\\begin{tabular}{|lrrr|\" + \"rrr|\"*(len(algo_list)*3) + \"}\\n\"\n",
    "    shead+= \"\\\\hline\\n\"\n",
    "    shead+= \" & & &\"\n",
    "    salgs = \"\\\\rule{0pt}{.4cm}Class & n & d & Avg.Bins\"\n",
    "    for alg in algo_list:\n",
    "        a1, a2, a3 = generate_algo_shortnames(alg)\n",
    "        shead+= \" & \\multicolumn{3}{c|}{\" + a1 + \"} & \\multicolumn{3}{c|}{\" + a2 + \"} & \\multicolumn{3}{c|}{\" + a3 + \"}\"\n",
    "        salgs += \" & \\%err & Diff & Time & \\%err & Diff & Time & \\%err & Diff & Time\"\n",
    "    shead+= \"\\\\\\\\\\n\" + salgs + \"\\\\\\\\\\n\\hline\\n\"\n",
    "\n",
    "    sbody = \"\"\n",
    "    for c in class_range:\n",
    "        cfirst = str(c)\n",
    "        sbody+= cfirst\n",
    "        for n in n_range:\n",
    "            sbody+= \"\\\\rule{0pt}{.6cm} & \" + str(n)\n",
    "            smid = \" &\"\n",
    "            for d in [3, 5, 10]:\n",
    "                smid+= f\" {d} & {df.loc[cfirst,n,d]['avg_best']:.1f}\"\n",
    "                for base_alg in algo_list:\n",
    "                    l = generate_algo_names(base_alg)\n",
    "                    for alg in l:\n",
    "                        smid+= f\" & {df.loc[cfirst,n,d][alg+'_eps']:.1f} & {df.loc[cfirst,n,d][alg+'_diff']:.1f}\"\n",
    "                        smid+= f\" & {df.loc[cfirst,n,d][alg+'_time']:.1f}\"\n",
    "                sbody+= smid + \"\\\\\\\\\\n\"\n",
    "                smid = \" & &\"\n",
    "\n",
    "        sbody+= \"\\multicolumn{4}{|c|}{\\\\rule{0pt}{.5cm}Summary over all instances}\"\n",
    "        for base_alg in algo_list:\n",
    "            l = generate_algo_names(base_alg)\n",
    "            for alg in l:\n",
    "                sbody+= f\" & {df.loc[cfirst][alg+'_eps'].mean():.1f} & {df.loc[cfirst][alg+'_diff'].mean():.1f}\"\n",
    "                sbody+= f\" & {df.loc[cfirst][alg+'_time'].mean():.1f}\"\n",
    "        sbody+= \"\\\\\\\\\\n\" + \"\\\\hline\\n\"\n",
    "        \n",
    "    sfull = shead + sbody + \"\\end{tabular}\\n\\end{table}\\n\\end{landscape}\"\n",
    "    \n",
    "    return sfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5d5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panigrahy instances\n",
    "s1 = generate_table_avg(table_df_P,\n",
    "        [\"FFD-SumSq-Unit\", \"WFD-T1-SumSqLoad-Unit\"],\n",
    "        [1, 2, 3],\n",
    "        [20, 120, 500],\n",
    "        #[20, 40, 60, 120, 250, 500],\n",
    "        \"Unit and Average weights - Panigrahy instances\", \"tab:avg-P11\")\n",
    "write_table(table_path / \"avg-P11.tex\", s1)\n",
    "\n",
    "# Panigrahy instances\n",
    "s2 = generate_table_avg(table_df_P,\n",
    "        [\"FFD-SumSq-Unit\", \"WFD-T1-SumSqLoad-Unit\"],\n",
    "        [4, 5, 6],\n",
    "        [20, 120, 500],\n",
    "        #[20, 40, 60, 120, 250, 500],\n",
    "        \"Unit and Average weights - Panigrahy instances\", \"tab:avg-P21\")\n",
    "write_table(table_path / \"avg-P21.tex\", s2)\n",
    "\n",
    "# Panigrahy instances\n",
    "s3 = generate_table_avg(table_df_P,\n",
    "        [\"FFD-SumSq-Unit\", \"WFD-T1-SumSqLoad-Unit\"],\n",
    "        [7, 8, 9],\n",
    "        [20, 120, 500],\n",
    "        #[20, 40, 60, 120, 250, 500],\n",
    "        \"Unit and Average weights - Panigrahy instances\", \"tab:avg-P31\")\n",
    "write_table(table_path / \"avg-P31.tex\", s3)\n",
    "\n",
    "\n",
    "\n",
    "# Panigrahy instances\n",
    "s1 = generate_table_avg(table_df_P,\n",
    "        [\"BCS-DP1-Unit\", \"BIM-BS-DP3-Unit\"],\n",
    "        [1, 2, 3],\n",
    "        [20, 120, 500],\n",
    "        #[20, 40, 60, 120, 250, 500],\n",
    "        \"Unit and Average weights - Panigrahy instances\", \"tab:avg-P12\")\n",
    "write_table(table_path / \"avg-P12.tex\", s1)\n",
    "\n",
    "# Panigrahy instances\n",
    "s2 = generate_table_avg(table_df_P,\n",
    "        [\"BCS-DP1-Unit\", \"BIM-BS-DP3-Unit\"],\n",
    "        [4, 5, 6],\n",
    "        [20, 120, 500],\n",
    "        #[20, 40, 60, 120, 250, 500],\n",
    "        \"Unit and Average weights - Panigrahy instances\", \"tab:avg-P22\")\n",
    "write_table(table_path / \"avg-P22.tex\", s2)\n",
    "\n",
    "# Panigrahy instances\n",
    "s3 = generate_table_avg(table_df_P,\n",
    "        [\"BCS-DP1-Unit\", \"BIM-BS-DP3-Unit\"],\n",
    "        [7, 8, 9],\n",
    "        [20, 120, 500],\n",
    "        #[20, 40, 60, 120, 250, 500],\n",
    "        \"Unit and Average weights - Panigrahy instances\", \"tab:avg-P32\")\n",
    "write_table(table_path / \"avg-P32.tex\", s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc729ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hetero instances\n",
    "s1 = generate_table_avg(table_df_H,\n",
    "        [\"FFD-SumSq-Unit\", \"WFD-T1-SumSqLoad-Unit\"],\n",
    "        [1, 2, 3],\n",
    "        [20, 120, 500],\n",
    "        #[20, 40, 60, 120, 250, 500],\n",
    "        \"Unit and Average weights - Hetero instances\", \"tab:avg-H11\")\n",
    "write_table(table_path / \"avg-H11.tex\", s1)\n",
    "\n",
    "s2 = generate_table_avg(table_df_H,\n",
    "        [\"FFD-SumSq-Unit\", \"WFD-T1-SumSqLoad-Unit\"],\n",
    "        [4, 5, 6],\n",
    "        [20, 120, 500],\n",
    "        #[20, 40, 60, 120, 250, 500],\n",
    "        \"Unit and Average weights - Hetero instances\", \"tab:avg-H21\")\n",
    "write_table(table_path / \"avg-H21.tex\", s2)\n",
    "\n",
    "\n",
    "\n",
    "# Hetero instances\n",
    "s1 = generate_table_avg(table_df_H,\n",
    "        [\"BCS-DP1-Unit\", \"BIM-BS-DP3-Unit\"],\n",
    "        [1, 2, 3],\n",
    "        [20, 120, 500],\n",
    "        #[20, 40, 60, 120, 250, 500],\n",
    "        \"Unit and Average weights - Hetero instances\", \"tab:avg-H12\")\n",
    "write_table(table_path / \"avg-H12.tex\", s1)\n",
    "\n",
    "s2 = generate_table_avg(table_df_H,\n",
    "        [\"BCS-DP1-Unit\", \"BIM-BS-DP3-Unit\"],\n",
    "        [4, 5, 6],\n",
    "        [20, 120, 500],\n",
    "        #[20, 40, 60, 120, 250, 500],\n",
    "        \"Unit and Average weights - Hetero instances\", \"tab:avg-H22\")\n",
    "write_table(table_path / \"avg-H22.tex\", s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eda608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triplet instances\n",
    "s1 = generate_table_avg(table_df_T,\n",
    "        [\"FFD-SumSq-Unit\", \"WFD-T1-SumSqLoad-Unit\"],\n",
    "        ['C', 'F'],\n",
    "        [60, 120, 249, 501],\n",
    "        \"Unit and Average weights - Triplet instances\", \"tab:avg-T11\")\n",
    "write_table(table_path / \"avg-T11.tex\", s1)\n",
    "\n",
    "\n",
    "# Triplet instances\n",
    "s1 = generate_table_avg(table_df_T,\n",
    "        [\"BCS-DP1-Unit\", \"BIM-BS-DP3-Unit\"],\n",
    "        ['C', 'F'],\n",
    "        [60, 120, 249, 501],\n",
    "        \"Unit and Average weights - Triplet instances\", \"tab:avg-T12\")\n",
    "write_table(table_path / \"avg-T12.tex\", s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9128aec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1737be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e280ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553170ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49d82ff7",
   "metadata": {},
   "source": [
    "# Old cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3782228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sup(x):\n",
    "    return x[x > 0].count()\n",
    "\n",
    "def my_eq(x):\n",
    "    return x[x == 0].count()\n",
    "\n",
    "def my_low(x):\n",
    "    return x[x < 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cecedc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_diff(df, list1, list2):\n",
    "    a = df[list1]\n",
    "    b = df[list2]\n",
    "    b.columns = a.columns\n",
    "    df_diff = (a - b).agg(['mean', 'std', my_sup, my_eq, my_low])\n",
    "    return df_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9bc861",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b858c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [x for x in alg_names if \"WFD\" in x and \"SumSqLoad\" in x and not \"T3\" in x]\n",
    "l2 = [x for x in alg_names if \"BFD\" in x and \"SumSq\" in x and not \"Load\" in x and not \"T3\" in x]\n",
    "print(len(l1), len(l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aacca0",
   "metadata": {},
   "source": [
    "## Compare BFD with SumSqLoad VS WFD SumSq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869f17d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4503bcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [x for x in alg_names if \"WFD\" in x and \"SumSqLoad\" in x and not \"T3\" in x]\n",
    "l2 = [x for x in alg_names if \"BFD\" in x and \"SumSq\" in x and not \"Load\" in x and not \"T3\" in x]\n",
    "print(len(l1), len(l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5c993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = make_diff(df, [\"\"], [\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3160582",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d154798e",
   "metadata": {},
   "source": [
    "## Compare bin-based weights with dynamic item-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78cfb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0eea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_bin = [x for x in alg_names if \"-Bin\" in x]\n",
    "list_dyn = [x.replace(\"Bin\",\"Dyn\") for x in list_bin]\n",
    "#print(list_bin)\n",
    "#print(list_dyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf04ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = make_diff(df, list_bin, list_dyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d5e04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bin > Dyn:\", df_diff.loc[\"my_sup\"].mean())\n",
    "print(\"Bin = Dyn:\", df_diff.loc[\"my_eq\"].mean())\n",
    "print(\"Bin < Dyn:\", df_diff.loc[\"my_low\"].mean())\n",
    "print(\"Overall mean:\", df_diff.loc[\"mean\"].mean())\n",
    "print(\"Overall std:\", df_diff.loc[\"mean\"].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(1,7):\n",
    "    df_diff = make_diff(df[df[\"class\"] == str(c)], list_bin, list_dyn)\n",
    "    print(\"Class\", c)\n",
    "    print(\"\\tBin > Dyn:\", df_diff.loc[\"my_sup\"].mean())\n",
    "    print(\"\\tBin = Dyn:\", df_diff.loc[\"my_eq\"].mean())\n",
    "    print(\"\\tBin < Dyn:\", df_diff.loc[\"my_low\"].mean())\n",
    "    print(\"\\tOverall mean:\", df_diff.loc[\"mean\"].mean())\n",
    "    print(\"\\tOverall std:\", df_diff.loc[\"mean\"].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d91700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92782d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"class\"] == \"1\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c8a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1018681",
   "metadata": {},
   "source": [
    "# Compare Static VS Dynamic weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, alg_names = load_df(file_P, with_classes=True, filter_centric=True)\n",
    "print(f\"loaded {len(alg_names)} algos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dc07c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dyn = [x for x in alg_names if \"Dyn\" in x]\n",
    "list_static = [x[:-4] for x in list_dyn]\n",
    "nb_algos = len(list_dyn)\n",
    "print(f\"{nb_algos} dynamic algos\")\n",
    "\n",
    "df_diff = make_diff(list_static, list_dyn)\n",
    "\n",
    "print(\"Static > Dynamic:\", df_diff.loc[\"my_sup\"].mean())\n",
    "print(\"Static = Dynamic:\", df_diff.loc[\"my_eq\"].mean())\n",
    "print(\"Static < Dynamic:\", df_diff.loc[\"my_low\"].mean())\n",
    "print(\"Overall mean:\", df_diff.loc[\"mean\"].mean())\n",
    "print(\"Overall std:\", df_diff.loc[\"mean\"].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef27750",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eca5c8a",
   "metadata": {},
   "source": [
    "# Compare BFD-T1 vs BFD-T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83714e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_T2 = [x for x in alg_names if \"BFD-T2\" in x]\n",
    "list_T1 = [x.replace('2','1') for x in list_T2]\n",
    "nb_algos = len(list_T2)\n",
    "print(f\"{nb_algos} BFD T2 algos\")\n",
    "\n",
    "df_diff = make_diff(list_T1, list_T2)\n",
    "\n",
    "print(\"T1 > T2:\", df_diff.loc[\"my_sup\"].mean())\n",
    "print(\"T1 = T2:\", df_diff.loc[\"my_eq\"].mean())\n",
    "print(\"T1 < T2:\", df_diff.loc[\"my_low\"].mean())\n",
    "print(\"Overall mean:\", df_diff.loc[\"mean\"].mean())\n",
    "print(\"Overall std:\", df_diff.loc[\"mean\"].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b13c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c030fde",
   "metadata": {},
   "source": [
    "# Compare WFD-T1 vs WFD-T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9713aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_T2 = [x for x in alg_names if \"WFD-T2\" in x]\n",
    "list_T1 = [x.replace('2','1') for x in list_T2]\n",
    "nb_algos = len(list_T2)\n",
    "print(f\"{nb_algos} WFD T2 algos\")\n",
    "\n",
    "df_diff = make_diff(list_T1, list_T2)\n",
    "\n",
    "print(\"T1 > T2:\", df_diff.loc[\"my_sup\"].mean())\n",
    "print(\"T1 = T2:\", df_diff.loc[\"my_eq\"].mean())\n",
    "print(\"T1 < T2:\", df_diff.loc[\"my_low\"].mean())\n",
    "print(\"Overall mean:\", df_diff.loc[\"mean\"].mean())\n",
    "print(\"Overall std:\", df_diff.loc[\"mean\"].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c420d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8653e4",
   "metadata": {},
   "source": [
    "# Compare BFD-T1 vs WFD-T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5907bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_BFD = [x for x in alg_names if \"BFD-T1\" in x]\n",
    "list_WFD = [x for x in alg_names if \"WFD-T1\" in x]\n",
    "nb_algos = len(list_BFD)\n",
    "print(f\"{nb_algos} BFD algos, {len(list_WFD)} WFD algos\")\n",
    "\n",
    "df_diff = make_diff(list_BFD, list_WFD)\n",
    "\n",
    "print(\"BFD > WFD:\", df_diff.loc[\"my_sup\"].mean())\n",
    "print(\"BFD = WFD:\", df_diff.loc[\"my_eq\"].mean())\n",
    "print(\"BFD < WFD:\", df_diff.loc[\"my_low\"].mean())\n",
    "print(\"Overall mean:\", df_diff.loc[\"mean\"].mean())\n",
    "print(\"Overall std:\", df_diff.loc[\"mean\"].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585c263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e87ab0",
   "metadata": {},
   "source": [
    "# Compare BCS algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0424e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "family_dict = create_family_dict(alg_names)\n",
    "print(family_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f926f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_DP1 = family_dict[\"BCS-DP1\"]\n",
    "for fam in ['BCS-DP2', 'BCS-DP3', 'BCS-NormDP', 'BCS-L2Norm', 'BCS-TFSum', 'BCS-TFMin']:\n",
    "    list_cmp = family_dict[fam]\n",
    "    df_diff = make_diff(list_DP1, list_cmp)\n",
    "    print(\"Compare DP1 with\", fam)\n",
    "    print(\"\\tDP1 > other:\", df_diff.loc[\"my_sup\"].mean())\n",
    "    print(\"\\tDP1 = other:\", df_diff.loc[\"my_eq\"].mean())\n",
    "    print(\"\\tDP1 < other:\", df_diff.loc[\"my_low\"].mean())\n",
    "    print(\"\\tOverall mean:\", df_diff.loc[\"mean\"].mean())\n",
    "    print(\"\\tOverall std:\", df_diff.loc[\"mean\"].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba89b1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c223a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a52a52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511a910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-omaha",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-marketplace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-mongolia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e088e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc74c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da91c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
